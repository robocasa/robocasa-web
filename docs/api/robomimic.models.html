
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>robomimic.models package &#8212; robomimic 0.3 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../static/pygments.css" />
    <link rel="stylesheet" href="../static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../static/documentation_options.js"></script>
    <script src="../static/jquery.js"></script>
    <script src="../static/underscore.js"></script>
    <script src="../static/doctools.js"></script>
    <script src="../static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="robomimic.utils package" href="robomimic.utils.html" />
    <link rel="prev" title="robomimic.envs package" href="robomimic.envs.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../static/robomimic_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">robomimic 0.3 documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/implemented_algorithms.html">
   Implemented Algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/getting_started.html">
   Getting Started
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Datasets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/robomimic_v0.1.html">
   robomimic v0.1 (CoRL 2021)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/robosuite.html">
   robosuite Datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/d4rl.html">
   D4RL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/momart.html">
   MOMART Datasets and Experiments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/roboturk_pilot.html">
   RoboTurk Pilot
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Pretrained Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../model_zoo/robomimic_v0.1.html">
   robomimic-v0.1
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/configs.html">
   Configuring and Launching Training Runs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/viewing_results.html">
   Logging and Viewing Training Results
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/hyperparam_scan.html">
   Running Hyperparameter Scans
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/reproducing_experiments.html">
   Reproducing Published Experiments and Results
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/dataset_contents.html">
   Dataset Contents and Visualization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/training_transformers.html">
   Training Transformers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/using_pretrained_models.html">
   Using Pretrained Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/observations.html">
   Multimodal Observations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/pretrained_representations.html">
   Pre-trained Visual Representations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/custom_algorithms.html">
   Implementing Custom Algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/tensor_collections.html">
   Operations over Tensor Collections
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Modules
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../modules/overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../modules/dataset.html">
   SequenceDataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../modules/algorithms.html">
   Algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../modules/models.html">
   Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../modules/configs.html">
   Configs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../modules/environments.html">
   Environments
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Source API
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="robomimic.html">
   robomimic package
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="robomimic.algo.html">
     robomimic.algo package
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="robomimic.config.html">
     robomimic.config package
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="robomimic.envs.html">
     robomimic.envs package
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     robomimic.models package
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="robomimic.utils.html">
     robomimic.utils package
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Miscellaneous
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../miscellaneous/troubleshooting.html">
   Troubleshooting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../miscellaneous/contributing.html">
   Contributing Guidelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../miscellaneous/team.html">
   Team
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../miscellaneous/acknowledgments.html">
   Acknowledgments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../miscellaneous/references.html">
   Projects using robomimic
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Previous Versions
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../versions/v0.2.html">
   v0.2
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../sources/api/robomimic.models.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#submodules">
   Submodules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.base_nets">
   robomimic.models.base_nets module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.distributions">
   robomimic.models.distributions module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.obs_core">
   robomimic.models.obs_core module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.obs_nets">
   robomimic.models.obs_nets module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.policy_nets">
   robomimic.models.policy_nets module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.transformers">
   robomimic.models.transformers module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.vae_nets">
   robomimic.models.vae_nets module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.value_nets">
   robomimic.models.value_nets module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models">
   Module contents
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>robomimic.models package</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#submodules">
   Submodules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.base_nets">
   robomimic.models.base_nets module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.distributions">
   robomimic.models.distributions module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.obs_core">
   robomimic.models.obs_core module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.obs_nets">
   robomimic.models.obs_nets module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.policy_nets">
   robomimic.models.policy_nets module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.transformers">
   robomimic.models.transformers module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.vae_nets">
   robomimic.models.vae_nets module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models.value_nets">
   robomimic.models.value_nets module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-robomimic.models">
   Module contents
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="robomimic-models-package">
<h1>robomimic.models package<a class="headerlink" href="#robomimic-models-package" title="Permalink to this headline">#</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">#</a></h2>
</section>
<section id="module-robomimic.models.base_nets">
<span id="robomimic-models-base-nets-module"></span><h2>robomimic.models.base_nets module<a class="headerlink" href="#module-robomimic.models.base_nets" title="Permalink to this headline">#</a></h2>
<p>Contains torch Modules that correspond to basic network building blocks, like
MLP, RNN, and CNN backbones.</p>
<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Conv1dBase">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">Conv1dBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(32,</span> <span class="pre">64,</span> <span class="pre">64)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(8,</span> <span class="pre">4,</span> <span class="pre">2)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(4,</span> <span class="pre">2,</span> <span class="pre">1)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">conv_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Conv1dBase" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Base class for stacked Conv1d layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_channel</strong> (<em>int</em>) – Number of channels for inputs to this network</p></li>
<li><p><strong>activation</strong> (<em>None</em><em> or </em><em>str</em>) – Per-layer activation to use. Defaults to “relu”. Valid options are
currently {relu, None} for no activation</p></li>
<li><p><strong>out_channels</strong> (<em>list of int</em>) – Output channel size for each sequential Conv1d layer</p></li>
<li><p><strong>kernel_size</strong> (<em>list of int</em>) – Kernel sizes for each sequential Conv1d layer</p></li>
<li><p><strong>stride</strong> (<em>list of int</em>) – Stride sizes for each sequential Conv1d layer</p></li>
<li><p><strong>conv_kwargs</strong> (<em>dict</em>) – additional nn.Conv1D args to use, in list form, where the ith element corresponds to the
argument to be passed to the ith Conv1D layer.
See <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html">https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html</a> for specific possible arguments.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Conv1dBase.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Conv1dBase.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Conv1dBase.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Conv1dBase.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Conv1dBase.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.Conv1dBase.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.ConvBase">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">ConvBase</span></span><a class="headerlink" href="#robomimic.models.base_nets.ConvBase" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Base class for ConvNets.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.ConvBase.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.ConvBase.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.ConvBase.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.ConvBase.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.ConvBase.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.ConvBase.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.CoordConv2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">CoordConv2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'zeros'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coord_encoding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'position'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.conv.Conv2d</span></code>, <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>2D Coordinate Convolution</p>
<p>Source: An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution
<a class="reference external" href="https://arxiv.org/abs/1807.03247">https://arxiv.org/abs/1807.03247</a>
(e.g. adds 2 channels per input feature map corresponding to (x, y) location on map)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.CoordConv2d.bias">
<span class="sig-name descname"><span class="pre">bias</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.bias" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.CoordConv2d.dilation">
<span class="sig-name descname"><span class="pre">dilation</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.dilation" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.CoordConv2d.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.CoordConv2d.groups">
<span class="sig-name descname"><span class="pre">groups</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.groups" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.CoordConv2d.kernel_size">
<span class="sig-name descname"><span class="pre">kernel_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.kernel_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.CoordConv2d.out_channels">
<span class="sig-name descname"><span class="pre">out_channels</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.out_channels" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.CoordConv2d.output_padding">
<span class="sig-name descname"><span class="pre">output_padding</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.output_padding" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.CoordConv2d.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.CoordConv2d.padding">
<span class="sig-name descname"><span class="pre">padding</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.padding" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.CoordConv2d.padding_mode">
<span class="sig-name descname"><span class="pre">padding_mode</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.padding_mode" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.CoordConv2d.stride">
<span class="sig-name descname"><span class="pre">stride</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.stride" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.CoordConv2d.transposed">
<span class="sig-name descname"><span class="pre">transposed</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.transposed" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.CoordConv2d.weight">
<span class="sig-name descname"><span class="pre">weight</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.Tensor</span></em><a class="headerlink" href="#robomimic.models.base_nets.CoordConv2d.weight" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.FeatureAggregator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">FeatureAggregator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">agg_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'avg'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.FeatureAggregator" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Helpful class for aggregating features across a dimension. This is useful in
practice when training models that break an input image up into several patches
since features can be extraced per-patch using the same encoder and then
aggregated using this module.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.FeatureAggregator.clear_weight">
<span class="sig-name descname"><span class="pre">clear_weight</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.FeatureAggregator.clear_weight" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.FeatureAggregator.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.FeatureAggregator.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Forward pooling pass.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.FeatureAggregator.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.FeatureAggregator.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.FeatureAggregator.set_weight">
<span class="sig-name descname"><span class="pre">set_weight</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.FeatureAggregator.set_weight" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.FeatureAggregator.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.FeatureAggregator.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.MLP">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">MLP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_dims=()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_func=&lt;class</span> <span class="pre">'torch.nn.modules.linear.Linear'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_func_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropouts=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalization=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_activation=None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.MLP" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Base class for simple Multi-Layer Perceptrons.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.MLP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.MLP.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Forward pass.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.MLP.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.MLP.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.MLP.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.MLP.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.MVPConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">MVPConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mvp_model_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'vitb-mae-egosoup'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freeze</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.MVPConv" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.ConvBase" title="robomimic.models.base_nets.ConvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.ConvBase</span></code></a></p>
<p>Base class for ConvNets pretrained with MVP (<a class="reference external" href="https://arxiv.org/abs/2203.06173">https://arxiv.org/abs/2203.06173</a>)</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.MVPConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.MVPConv.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.MVPConv.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.MVPConv.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.
:param input_shape: shape of input. Does not include batch dimension.</p>
<blockquote>
<div><p>Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.MVPConv.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.MVPConv.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Module">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">Module</span></span><a class="headerlink" href="#robomimic.models.base_nets.Module" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Base class for networks. The only difference from torch.nn.Module is that it
requires implementing &#64;output_shape.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Module.output_shape">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Module.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Module.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.Module.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Parameter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">Parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init_tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Parameter" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>A class that is a thin wrapper around a torch.nn.Parameter to make for easy saving
and optimization.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Parameter.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Parameter.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Forward call just returns the parameter tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Parameter.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Parameter.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Parameter.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.Parameter.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.R3MConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">R3MConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r3m_model_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'resnet18'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freeze</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.R3MConv" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.ConvBase" title="robomimic.models.base_nets.ConvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.ConvBase</span></code></a></p>
<p>Base class for ConvNets pretrained with R3M (<a class="reference external" href="https://arxiv.org/abs/2203.12601">https://arxiv.org/abs/2203.12601</a>)</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.R3MConv.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.R3MConv.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.
:param input_shape: shape of input. Does not include batch dimension.</p>
<blockquote>
<div><p>Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.R3MConv.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.R3MConv.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.RNN_Base">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">RNN_Base</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_hidden_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'LSTM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_step_net</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.RNN_Base" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>A wrapper class for a multi-step RNN and a per-step network.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.RNN_Base.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_init_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.RNN_Base.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Forward a sequence of inputs through the RNN and the per-step network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>torch.Tensor</em>) – tensor input of shape [B, T, D], where D is the RNN input size</p></li>
<li><p><strong>rnn_init_state</strong> – rnn hidden state, initialize to zero state if set to None</p></li>
<li><p><strong>return_state</strong> (<em>bool</em>) – whether to return hidden state</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>outputs of the per_step_net</p>
<p>rnn_state: return rnn state at the end if return_state is set to True</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>outputs</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.RNN_Base.forward_step">
<span class="sig-name descname"><span class="pre">forward_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_state</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.RNN_Base.forward_step" title="Permalink to this definition">#</a></dt>
<dd><p>Forward a single step input through the RNN and per-step network, and return the new hidden state.
:param inputs: tensor input of shape [B, D], where D is the RNN input size
:type inputs: torch.Tensor
:param rnn_state: rnn hidden state, initialize to zero state if set to None</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><p>outputs of the per_step_net</p>
<p>rnn_state: return the new rnn state</p>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>outputs</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.RNN_Base.get_rnn_init_state">
<span class="sig-name descname"><span class="pre">get_rnn_init_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.RNN_Base.get_rnn_init_state" title="Permalink to this definition">#</a></dt>
<dd><p>Get a default RNN state (zeros)
:param batch_size: batch size dimension
:type batch_size: int
:param device: device the hidden state should be sent to.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>returns hidden state tensor or tuple of hidden state tensors</dt><dd><p>depending on the RNN type</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>hidden_state (torch.Tensor or tuple)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.RNN_Base.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.RNN_Base.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="robomimic.models.base_nets.RNN_Base.rnn_type">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">rnn_type</span></span><a class="headerlink" href="#robomimic.models.base_nets.RNN_Base.rnn_type" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.RNN_Base.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.RNN_Base.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.ResNet18Conv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">ResNet18Conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_coord_conv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.ResNet18Conv" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.ConvBase" title="robomimic.models.base_nets.ConvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.ConvBase</span></code></a></p>
<p>A ResNet18 block that can be used to process input images.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.ResNet18Conv.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.ResNet18Conv.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.ResNet18Conv.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.ResNet18Conv.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Sequential">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">Sequential</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">has_output_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Sequential" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.container.Sequential</span></code>, <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Compose multiple Modules together (defined above).</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Sequential.freeze">
<span class="sig-name descname"><span class="pre">freeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Sequential.freeze" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Sequential.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Sequential.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Sequential.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Sequential.train" title="Permalink to this definition">#</a></dt>
<dd><p>Sets the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation
mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module">Module</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Sequential.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.Sequential.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.ShallowConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">ShallowConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_channel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.ShallowConv" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.ConvBase" title="robomimic.models.base_nets.ConvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.ConvBase</span></code></a></p>
<p>A shallow convolutional encoder from <a class="reference external" href="https://rll.berkeley.edu/dsae/dsae.pdf">https://rll.berkeley.edu/dsae/dsae.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.ShallowConv.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.ShallowConv.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.ShallowConv.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.ShallowConv.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.SpatialMeanPool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">SpatialMeanPool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.SpatialMeanPool" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Module that averages inputs across all spatial dimensions (dimension 2 and after),
leaving only the batch and channel dimensions.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.SpatialMeanPool.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.SpatialMeanPool.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Forward pass - average across all dimensions except batch and channel.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.SpatialMeanPool.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.SpatialMeanPool.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.SpatialMeanPool.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.SpatialMeanPool.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.SpatialSoftmax">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">SpatialSoftmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_kp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learnable_temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.SpatialSoftmax" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.ConvBase" title="robomimic.models.base_nets.ConvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.ConvBase</span></code></a></p>
<p>Spatial Softmax Layer.</p>
<p>Based on Deep Spatial Autoencoders for Visuomotor Learning by Finn et al.
<a class="reference external" href="https://rll.berkeley.edu/dsae/dsae.pdf">https://rll.berkeley.edu/dsae/dsae.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.SpatialSoftmax.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.SpatialSoftmax.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Forward pass through spatial softmax layer. For each keypoint, a 2D spatial
probability distribution is created using a softmax, where the support is the
pixel locations. This distribution is used to compute the expected value of
the pixel location, which becomes a keypoint of dimension 2. K such keypoints
are created.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>mean keypoints of shape [B, K, 2], and possibly</dt><dd><p>keypoint variance of shape [B, K, 2, 2] corresponding to the covariance
under the 2D spatial softmax distribution</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>out (torch.Tensor or tuple)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.SpatialSoftmax.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.SpatialSoftmax.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.SpatialSoftmax.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.SpatialSoftmax.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Squeeze">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">Squeeze</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Squeeze" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Trivial class that squeezes the input. Useful for including in a nn.Sequential network</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Squeeze.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Squeeze.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Squeeze.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Squeeze.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Squeeze.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.Squeeze.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Unsqueeze">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">Unsqueeze</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Unsqueeze" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Trivial class that unsqueezes the input. Useful for including in a nn.Sequential network</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Unsqueeze.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Unsqueeze.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Unsqueeze.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.Unsqueeze.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.base_nets.Unsqueeze.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.base_nets.Unsqueeze.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="robomimic.models.base_nets.rnn_args_from_config">
<span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">rnn_args_from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rnn_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.rnn_args_from_config" title="Permalink to this definition">#</a></dt>
<dd><p>Takes a Config object corresponding to RNN settings
(for example <cite>config.algo.rnn</cite> in BCConfig) and extracts
rnn kwargs for instantiating rnn networks.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="robomimic.models.base_nets.transformer_args_from_config">
<span class="sig-prename descclassname"><span class="pre">robomimic.models.base_nets.</span></span><span class="sig-name descname"><span class="pre">transformer_args_from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">transformer_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.base_nets.transformer_args_from_config" title="Permalink to this definition">#</a></dt>
<dd><p>Takes a Config object corresponding to Transformer settings
(for example <cite>config.algo.transformer</cite> in BCConfig) and extracts
transformer kwargs for instantiating transformer networks.</p>
</dd></dl>

</section>
<section id="module-robomimic.models.distributions">
<span id="robomimic-models-distributions-module"></span><h2>robomimic.models.distributions module<a class="headerlink" href="#module-robomimic.models.distributions" title="Permalink to this headline">#</a></h2>
<p>Contains distribution models used as parts of other networks. These
classes usually inherit or emulate torch distributions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.distributions.DiscreteValueDistribution">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.distributions.</span></span><span class="sig-name descname"><span class="pre">DiscreteValueDistribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.DiscreteValueDistribution" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Extension to torch categorical probability distribution in order to keep track
of the support (categorical values, or in this case, value atoms). This is
used for distributional value networks.</p>
<dl class="py property">
<dt class="sig sig-object py" id="robomimic.models.distributions.DiscreteValueDistribution.logits">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logits</span></span><a class="headerlink" href="#robomimic.models.distributions.DiscreteValueDistribution.logits" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.distributions.DiscreteValueDistribution.mean">
<span class="sig-name descname"><span class="pre">mean</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.DiscreteValueDistribution.mean" title="Permalink to this definition">#</a></dt>
<dd><p>Categorical distribution mean, taking the value support into account.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="robomimic.models.distributions.DiscreteValueDistribution.probs">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">probs</span></span><a class="headerlink" href="#robomimic.models.distributions.DiscreteValueDistribution.probs" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.distributions.DiscreteValueDistribution.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.Size([])</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.DiscreteValueDistribution.sample" title="Permalink to this definition">#</a></dt>
<dd><p>Sample from the distribution. Make sure to return value atoms, not categorical class indices.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="robomimic.models.distributions.DiscreteValueDistribution.values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">values</span></span><a class="headerlink" href="#robomimic.models.distributions.DiscreteValueDistribution.values" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.distributions.DiscreteValueDistribution.variance">
<span class="sig-name descname"><span class="pre">variance</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.DiscreteValueDistribution.variance" title="Permalink to this definition">#</a></dt>
<dd><p>Categorical distribution variance, taking the value support into account.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.distributions.TanhWrappedDistribution">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.distributions.</span></span><span class="sig-name descname"><span class="pre">TanhWrappedDistribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_dist</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.TanhWrappedDistribution" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></p>
<p>Class that wraps another valid torch distribution, such that sampled values from the base distribution are
passed through a tanh layer. The corresponding (log) probabilities are also modified accordingly.
Tanh Normal distribution - adapted from rlkit and CQL codebase
(<a class="reference external" href="https://github.com/aviralkumar2907/CQL/blob/d67dbe9cf5d2b96e3b462b6146f249b3d6569796/d4rl/rlkit/torch/distributions.py#L6">https://github.com/aviralkumar2907/CQL/blob/d67dbe9cf5d2b96e3b462b6146f249b3d6569796/d4rl/rlkit/torch/distributions.py#L6</a>).</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.distributions.TanhWrappedDistribution.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_tanh_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.TanhWrappedDistribution.log_prob" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> (<em>torch.Tensor</em>) – some tensor to compute log probabilities for</p></li>
<li><p><strong>pre_tanh_value</strong> – If specified, will not calculate atanh manually from &#64;value. More numerically stable</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="robomimic.models.distributions.TanhWrappedDistribution.mean">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mean</span></span><a class="headerlink" href="#robomimic.models.distributions.TanhWrappedDistribution.mean" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the mean of the distribution.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.distributions.TanhWrappedDistribution.rsample">
<span class="sig-name descname"><span class="pre">rsample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.Size([])</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_pretanh_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.TanhWrappedDistribution.rsample" title="Permalink to this definition">#</a></dt>
<dd><p>Sampling in the reparameterization case - for differentiable samples.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.distributions.TanhWrappedDistribution.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.Size([])</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_pretanh_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.distributions.TanhWrappedDistribution.sample" title="Permalink to this definition">#</a></dt>
<dd><p>Gradients will and should <em>not</em> pass through this operation.
See <a class="reference external" href="https://github.com/pytorch/pytorch/issues/4620">https://github.com/pytorch/pytorch/issues/4620</a> for discussion.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="robomimic.models.distributions.TanhWrappedDistribution.stddev">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stddev</span></span><a class="headerlink" href="#robomimic.models.distributions.TanhWrappedDistribution.stddev" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the standard deviation of the distribution.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-robomimic.models.obs_core">
<span id="robomimic-models-obs-core-module"></span><h2>robomimic.models.obs_core module<a class="headerlink" href="#module-robomimic.models.obs_core" title="Permalink to this headline">#</a></h2>
<p>Contains torch Modules for core observation processing blocks
such as encoders (e.g. EncoderCore, VisualCore, ScanCore, …)
and randomizers (e.g. Randomizer, CropRandomizer).</p>
<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.obs_core.ColorRandomizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.obs_core.</span></span><span class="sig-name descname"><span class="pre">ColorRandomizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">brightness</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">contrast</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">saturation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hue</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.ColorRandomizer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.obs_core.Randomizer" title="robomimic.models.obs_core.Randomizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.obs_core.Randomizer</span></code></a></p>
<p>Randomly sample color jitter at input, and then average across color jtters at output.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.ColorRandomizer.get_batch_transform">
<span class="sig-name descname"><span class="pre">get_batch_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.ColorRandomizer.get_batch_transform" title="Permalink to this definition">#</a></dt>
<dd><p>Generates a batch transform, where each set of sample(s) along the batch (first) dimension will have the same
&#64;N unique ColorJitter transforms applied.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>N</strong> (<em>int</em>) – Number of ColorJitter transforms to apply per set of sample(s) along the batch (first) dimension</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Aggregated transform which will autoamtically apply a different ColorJitter transforms to</dt><dd><p>each sub-set of samples along batch dimension, assumed to be the FIRST dimension in the inputted tensor
Note: This function will MULTIPLY the first dimension by N</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Lambda</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.ColorRandomizer.get_transform">
<span class="sig-name descname"><span class="pre">get_transform</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.ColorRandomizer.get_transform" title="Permalink to this definition">#</a></dt>
<dd><p>Get a randomized transform to be applied on image.</p>
<p>Implementation taken directly from:</p>
<p><a class="reference external" href="https://github.com/pytorch/vision/blob/2f40a483d73018ae6e1488a484c5927f2b309969/torchvision/transforms/transforms.py#L1053-L1085">https://github.com/pytorch/vision/blob/2f40a483d73018ae6e1488a484c5927f2b309969/torchvision/transforms/transforms.py#L1053-L1085</a></p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Transform which randomly adjusts brightness, contrast and
saturation in a random order.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Transform</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.ColorRandomizer.output_shape_in">
<span class="sig-name descname"><span class="pre">output_shape_in</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.ColorRandomizer.output_shape_in" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module. Corresponds to
the &#64;forward_in operation, where raw inputs (usually observation modalities)
are passed in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.ColorRandomizer.output_shape_out">
<span class="sig-name descname"><span class="pre">output_shape_out</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.ColorRandomizer.output_shape_out" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module. Corresponds to
the &#64;forward_out operation, where processed inputs (usually encoded observation
modalities) are passed in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.obs_core.ColorRandomizer.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_core.ColorRandomizer.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.obs_core.CropRandomizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.obs_core.</span></span><span class="sig-name descname"><span class="pre">CropRandomizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crop_height</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">76</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crop_width</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">76</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_crops</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_enc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.CropRandomizer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.obs_core.Randomizer" title="robomimic.models.obs_core.Randomizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.obs_core.Randomizer</span></code></a></p>
<p>Randomly sample crops at input, and then average across crop features at output.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.CropRandomizer.output_shape_in">
<span class="sig-name descname"><span class="pre">output_shape_in</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.CropRandomizer.output_shape_in" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module. Corresponds to
the &#64;forward_in operation, where raw inputs (usually observation modalities)
are passed in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.CropRandomizer.output_shape_out">
<span class="sig-name descname"><span class="pre">output_shape_out</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.CropRandomizer.output_shape_out" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module. Corresponds to
the &#64;forward_out operation, where processed inputs (usually encoded observation
modalities) are passed in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.obs_core.CropRandomizer.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_core.CropRandomizer.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.obs_core.EncoderCore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.obs_core.</span></span><span class="sig-name descname"><span class="pre">EncoderCore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.EncoderCore" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Abstract class used to categorize all cores used to encode observations</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.obs_core.EncoderCore.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_core.EncoderCore.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.obs_core.GaussianNoiseRandomizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.obs_core.</span></span><span class="sig-name descname"><span class="pre">GaussianNoiseRandomizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">limits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.GaussianNoiseRandomizer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.obs_core.Randomizer" title="robomimic.models.obs_core.Randomizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.obs_core.Randomizer</span></code></a></p>
<p>Randomly sample gaussian noise at input, and then average across noises at output.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.GaussianNoiseRandomizer.output_shape_in">
<span class="sig-name descname"><span class="pre">output_shape_in</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.GaussianNoiseRandomizer.output_shape_in" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module. Corresponds to
the &#64;forward_in operation, where raw inputs (usually observation modalities)
are passed in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.GaussianNoiseRandomizer.output_shape_out">
<span class="sig-name descname"><span class="pre">output_shape_out</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.GaussianNoiseRandomizer.output_shape_out" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module. Corresponds to
the &#64;forward_out operation, where processed inputs (usually encoded observation
modalities) are passed in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.obs_core.GaussianNoiseRandomizer.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_core.GaussianNoiseRandomizer.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.obs_core.Randomizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.obs_core.</span></span><span class="sig-name descname"><span class="pre">Randomizer</span></span><a class="headerlink" href="#robomimic.models.obs_core.Randomizer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Base class for randomizer networks. Each randomizer should implement the &#64;output_shape_in,
&#64;output_shape_out, &#64;forward_in, and &#64;forward_out methods. The randomizer’s &#64;forward_in
method is invoked on raw inputs, and &#64;forward_out is invoked on processed inputs
(usually processed by a &#64;VisualCore instance). Note that the self.training property
can be used to change the randomizer’s behavior at train vs. test time.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.Randomizer.forward_in">
<span class="sig-name descname"><span class="pre">forward_in</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.Randomizer.forward_in" title="Permalink to this definition">#</a></dt>
<dd><p>Randomize raw inputs if training.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.Randomizer.forward_out">
<span class="sig-name descname"><span class="pre">forward_out</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.Randomizer.forward_out" title="Permalink to this definition">#</a></dt>
<dd><p>Processing for network outputs.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.Randomizer.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.Randomizer.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>This function is unused. See &#64;output_shape_in and &#64;output_shape_out.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.Randomizer.output_shape_in">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_shape_in</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.Randomizer.output_shape_in" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module. Corresponds to
the &#64;forward_in operation, where raw inputs (usually observation modalities)
are passed in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.Randomizer.output_shape_out">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_shape_out</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.Randomizer.output_shape_out" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module. Corresponds to
the &#64;forward_out operation, where processed inputs (usually encoded observation
modalities) are passed in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.obs_core.Randomizer.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_core.Randomizer.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.obs_core.ScanCore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.obs_core.</span></span><span class="sig-name descname"><span class="pre">ScanCore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conv_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conv_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flatten</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.ScanCore" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.obs_core.EncoderCore" title="robomimic.models.obs_core.EncoderCore"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.obs_core.EncoderCore</span></code></a>, <a class="reference internal" href="#robomimic.models.base_nets.ConvBase" title="robomimic.models.base_nets.ConvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.ConvBase</span></code></a></p>
<p>A network block that combines a Conv1D backbone network with optional pooling
and linear layers.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.ScanCore.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.ScanCore.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Forward pass through visual core.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.ScanCore.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.ScanCore.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.obs_core.ScanCore.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_core.ScanCore.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.obs_core.VisualCore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.obs_core.</span></span><span class="sig-name descname"><span class="pre">VisualCore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ResNet18Conv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'SpatialSoftmax'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flatten</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.VisualCore" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.obs_core.EncoderCore" title="robomimic.models.obs_core.EncoderCore"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.obs_core.EncoderCore</span></code></a>, <a class="reference internal" href="#robomimic.models.base_nets.ConvBase" title="robomimic.models.base_nets.ConvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.ConvBase</span></code></a></p>
<p>A network block that combines a visual backbone network with optional pooling
and linear layers.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.VisualCore.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.VisualCore.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Forward pass through visual core.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_core.VisualCore.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_core.VisualCore.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.obs_core.VisualCore.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_core.VisualCore.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-robomimic.models.obs_nets">
<span id="robomimic-models-obs-nets-module"></span><h2>robomimic.models.obs_nets module<a class="headerlink" href="#module-robomimic.models.obs_nets" title="Permalink to this headline">#</a></h2>
<p>Contains torch Modules that help deal with inputs consisting of multiple
modalities. This is extremely common when networks must deal with one or
more observation dictionaries, where each input dictionary can have
observation keys of a certain modality and shape.</p>
<p>As an example, an observation could consist of a flat “robot0_eef_pos” observation key,
and a 3-channel RGB “agentview_image” observation key.</p>
<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.MIMO_MLP">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.obs_nets.</span></span><span class="sig-name descname"><span class="pre">MIMO_MLP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_obs_group_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_func=&lt;class</span> <span class="pre">'torch.nn.modules.linear.Linear'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs=None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.MIMO_MLP" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Extension to MLP to accept multiple observation dictionaries as input and
to output dictionaries of tensors. Inputs are specified as a dictionary of
observation dictionaries, with each key corresponding to an observation group.</p>
<p>This module utilizes &#64;ObservationGroupEncoder to process the multiple input dictionaries and
&#64;ObservationDecoder to generate tensor dictionaries. The default behavior
for encoding the inputs is to process visual inputs with a learned CNN and concatenating
the flat encodings with the other flat inputs. The default behavior for generating
outputs is to use a linear layer branch to produce each modality separately
(including visual outputs).</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.MIMO_MLP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.MIMO_MLP.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Process each set of inputs in its own observation group.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>dict</em>) – a dictionary of dictionaries with one dictionary per
observation group. Each observation group’s dictionary should map
modality to torch.Tensor batches. Should be consistent with
&#64;self.input_obs_group_shapes.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>dictionary of output torch.Tensors, that corresponds</dt><dd><p>to &#64;self.output_shapes</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>outputs (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.MIMO_MLP.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.MIMO_MLP.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Returns output shape for this module, which is a dictionary instead
of a list since outputs are dictionaries.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.MIMO_MLP.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_nets.MIMO_MLP.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.MIMO_Transformer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.obs_nets.</span></span><span class="sig-name descname"><span class="pre">MIMO_Transformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_obs_group_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_embed_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_num_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_context_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_emb_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_attn_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_block_output_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_sinusoidal_embedding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_nn_parameter_for_timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.MIMO_Transformer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Extension to Transformer (based on GPT architecture) to accept multiple observation
dictionaries as input and to output dictionaries of tensors. Inputs are specified as
a dictionary of observation dictionaries, with each key corresponding to an observation group.
This module utilizes &#64;ObservationGroupEncoder to process the multiple input dictionaries and
&#64;ObservationDecoder to generate tensor dictionaries. The default behavior
for encoding the inputs is to process visual inputs with a learned CNN and concatenating
the flat encodings with the other flat inputs. The default behavior for generating
outputs is to use a linear layer branch to produce each modality separately
(including visual outputs).</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.MIMO_Transformer.embed_timesteps">
<span class="sig-name descname"><span class="pre">embed_timesteps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.MIMO_Transformer.embed_timesteps" title="Permalink to this definition">#</a></dt>
<dd><p>Computes timestep-based embeddings (aka positional embeddings) to add to embeddings.
:param embeddings: embeddings prior to positional embeddings are computed
:type embeddings: torch.Tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>positional embeddings to add to embeddings</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>time_embeddings (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.MIMO_Transformer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.MIMO_Transformer.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Process each set of inputs in its own observation group.
:param inputs: a dictionary of dictionaries with one dictionary per</p>
<blockquote>
<div><p>observation group. Each observation group’s dictionary should map
modality to torch.Tensor batches. Should be consistent with
&#64;self.input_obs_group_shapes. First two leading dimensions should
be batch and time [B, T, …] for each tensor.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>dictionary of output torch.Tensors, that corresponds</dt><dd><p>to &#64;self.output_shapes. Leading dimensions will be batch and time [B, T, …]
for each tensor.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>outputs (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.MIMO_Transformer.input_embedding">
<span class="sig-name descname"><span class="pre">input_embedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.MIMO_Transformer.input_embedding" title="Permalink to this definition">#</a></dt>
<dd><p>Process encoded observations into embeddings to pass to transformer,
Adds timestep-based embeddings (aka positional embeddings) to inputs.
:param inputs: outputs from observation encoder
:type inputs: torch.Tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>input embeddings to pass to transformer backbone.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>embeddings (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.MIMO_Transformer.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.MIMO_Transformer.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Returns output shape for this module, which is a dictionary instead
of a list since outputs are dictionaries.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.MIMO_Transformer.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_nets.MIMO_Transformer.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.ObservationDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.obs_nets.</span></span><span class="sig-name descname"><span class="pre">ObservationDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">decode_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_feat_dim</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationDecoder" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Module that can generate observation outputs by modality. Inputs are assumed
to be flat (usually outputs from some hidden layer). Each observation output
is generated with a linear layer from these flat inputs. Subclass this
module in order to implement more complex schemes for generating each
modality.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.ObservationDecoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feats</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationDecoder.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Predict each modality from input features, and reshape to each modality’s shape.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.ObservationDecoder.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationDecoder.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Returns output shape for this module, which is a dictionary instead
of a list since outputs are dictionaries.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.ObservationDecoder.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_nets.ObservationDecoder.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.ObservationEncoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.obs_nets.</span></span><span class="sig-name descname"><span class="pre">ObservationEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_activation=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationEncoder" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Module that processes inputs by observation key and then concatenates the processed
observation keys together. Each key is processed with an encoder head network.
Call &#64;register_obs_key to register observation keys with the encoder and then
finally call &#64;make to create the encoder networks.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.ObservationEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationEncoder.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Processes modalities according to the ordering in &#64;self.obs_shapes. For each
modality, it is processed with a randomizer (if present), an encoder
network (if present), and again with the randomizer (if present), flattened,
and then concatenated with the other processed modalities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>obs_dict</strong> (<em>OrderedDict</em>) – dictionary that maps modalities to torch.Tensor
batches that agree with &#64;self.obs_shapes. All modalities in
&#64;self.obs_shapes must be present, but additional modalities
can also be present.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>flat features of shape [B, D]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>feats (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.ObservationEncoder.make">
<span class="sig-name descname"><span class="pre">make</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationEncoder.make" title="Permalink to this definition">#</a></dt>
<dd><p>Creates the encoder networks and locks the encoder so that more modalities cannot be added.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.ObservationEncoder.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationEncoder.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the output shape of the encoder.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.ObservationEncoder.register_obs_key">
<span class="sig-name descname"><span class="pre">register_obs_key</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">randomizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_net_from</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationEncoder.register_obs_key" title="Permalink to this definition">#</a></dt>
<dd><p>Register an observation key that this encoder should be responsible for.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – modality name</p></li>
<li><p><strong>shape</strong> (<em>int tuple</em>) – shape of modality</p></li>
<li><p><strong>net_class</strong> (<em>str</em>) – name of class in base_nets.py that should be used
to process this observation key before concatenation. Pass None to flatten
and concatenate the observation key directly.</p></li>
<li><p><strong>net_kwargs</strong> (<em>dict</em>) – arguments to pass to &#64;net_class</p></li>
<li><p><strong>net</strong> (<em>Module instance</em>) – if provided, use this Module to process the observation key
instead of creating a different net</p></li>
<li><p><strong>randomizer</strong> (<em>Randomizer instance</em>) – if provided, use this Module to augment observation keys
coming in to the encoder, and possibly augment the processed output as well</p></li>
<li><p><strong>share_net_from</strong> (<em>str</em>) – if provided, use the same instance of &#64;net_class
as another observation key. This observation key must already exist in this encoder.
Warning: Note that this does not share the observation key randomizer</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.ObservationEncoder.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_nets.ObservationEncoder.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.ObservationGroupEncoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.obs_nets.</span></span><span class="sig-name descname"><span class="pre">ObservationGroupEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_group_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_activation=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs=None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationGroupEncoder" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>This class allows networks to encode multiple observation dictionaries into a single
flat, concatenated vector representation. It does this by assigning each observation
dictionary (observation group) an &#64;ObservationEncoder object.</p>
<p>The class takes a dictionary of dictionaries, &#64;observation_group_shapes.
Each key corresponds to a observation group (e.g. ‘obs’, ‘subgoal’, ‘goal’)
and each OrderedDict should be a map between modalities and
expected input shapes (e.g. { ‘image’ : (3, 120, 160) }).</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.ObservationGroupEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationGroupEncoder.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Process each set of inputs in its own observation group.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>dict</em>) – dictionary that maps observation groups to observation
dictionaries of torch.Tensor batches that agree with
&#64;self.observation_group_shapes. All observation groups in
&#64;self.observation_group_shapes must be present, but additional
observation groups can also be present. Note that these are specified
as kwargs for ease of use with networks that name each observation
stream in their forward calls.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>flat outputs of shape [B, D]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>outputs (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.ObservationGroupEncoder.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.ObservationGroupEncoder.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the output shape of this encoder.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.ObservationGroupEncoder.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_nets.ObservationGroupEncoder.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.RNN_MIMO_MLP">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.obs_nets.</span></span><span class="sig-name descname"><span class="pre">RNN_MIMO_MLP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_obs_group_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_hidden_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_type='LSTM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_activation=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_func=&lt;class</span> <span class="pre">'torch.nn.modules.linear.Linear'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_step=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs=None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.RNN_MIMO_MLP" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>A wrapper class for a multi-step RNN and a per-step MLP and a decoder.</p>
<p>Structure: [encoder -&gt; rnn -&gt; mlp -&gt; decoder]</p>
<p>All temporal inputs are processed by a shared &#64;ObservationGroupEncoder,
followed by an RNN, and then a per-step multi-output MLP.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.RNN_MIMO_MLP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rnn_init_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.RNN_MIMO_MLP.forward" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>dict</em>) – a dictionary of dictionaries with one dictionary per
observation group. Each observation group’s dictionary should map
modality to torch.Tensor batches. Should be consistent with
&#64;self.input_obs_group_shapes. First two leading dimensions should
be batch and time [B, T, …] for each tensor.</p></li>
<li><p><strong>rnn_init_state</strong> – rnn hidden state, initialize to zero state if set to None</p></li>
<li><p><strong>return_state</strong> (<em>bool</em>) – whether to return hidden state</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>dictionary of output torch.Tensors, that corresponds</dt><dd><p>to &#64;self.output_shapes. Leading dimensions will be batch and time [B, T, …]
for each tensor.</p>
</dd>
</dl>
<p>rnn_state (torch.Tensor or tuple): return the new rnn state (if &#64;return_state)</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>outputs (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.RNN_MIMO_MLP.forward_step">
<span class="sig-name descname"><span class="pre">forward_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rnn_state</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.RNN_MIMO_MLP.forward_step" title="Permalink to this definition">#</a></dt>
<dd><p>Unroll network over a single timestep.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>dict</em>) – expects same modalities as &#64;self.input_shapes, with
additional batch dimension (but NOT time), since this is a
single time step.</p></li>
<li><p><strong>rnn_state</strong> (<em>torch.Tensor</em>) – rnn hidden state</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>dictionary of output torch.Tensors, that corresponds</dt><dd><p>to &#64;self.output_shapes. Does not contain time dimension.</p>
</dd>
</dl>
<p>rnn_state: return the new rnn state</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>outputs (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.RNN_MIMO_MLP.get_rnn_init_state">
<span class="sig-name descname"><span class="pre">get_rnn_init_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.RNN_MIMO_MLP.get_rnn_init_state" title="Permalink to this definition">#</a></dt>
<dd><p>Get a default RNN state (zeros)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size dimension</p></li>
<li><p><strong>device</strong> – device the hidden state should be sent to.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>returns hidden state tensor or tuple of hidden state tensors</dt><dd><p>depending on the RNN type</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>hidden_state (torch.Tensor or tuple)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.RNN_MIMO_MLP.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.RNN_MIMO_MLP.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Returns output shape for this module, which is a dictionary instead
of a list since outputs are dictionaries.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>dict</em>) – dictionary of dictionaries, where each top-level key
corresponds to an observation group, and the low-level dictionaries
specify the shape for each modality in an observation dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.RNN_MIMO_MLP.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.obs_nets.RNN_MIMO_MLP.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="robomimic.models.obs_nets.obs_encoder_factory">
<span class="sig-prename descclassname"><span class="pre">robomimic.models.obs_nets.</span></span><span class="sig-name descname"><span class="pre">obs_encoder_factory</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_activation=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs=None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.obs_nets.obs_encoder_factory" title="Permalink to this definition">#</a></dt>
<dd><p>Utility function to create an &#64;ObservationEncoder from kwargs specified in config.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_shapes</strong> (<em>OrderedDict</em>) – a dictionary that maps observation key to
expected shapes for observations.</p></li>
<li><p><strong>feature_activation</strong> – non-linearity to apply after each obs net - defaults to ReLU. Pass
None to apply no activation.</p></li>
<li><p><strong>encoder_kwargs</strong> (<em>dict</em><em> or </em><em>None</em>) – <p>If None, results in default encoder_kwargs being applied. Otherwise, should be
nested dictionary containing relevant per-modality information for encoder networks.
Should be of form:</p>
<dl>
<dt>obs_modality1: dict</dt><dd><p>feature_dimension: int
core_class: str
core_kwargs: dict</p>
<blockquote>
<div></div></blockquote>
<p>obs_randomizer_class: str
obs_randomizer_kwargs: dict</p>
<blockquote>
<div></div></blockquote>
</dd>
<dt>obs_modality2: dict</dt><dd><p>…</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-robomimic.models.policy_nets">
<span id="robomimic-models-policy-nets-module"></span><h2>robomimic.models.policy_nets module<a class="headerlink" href="#module-robomimic.models.policy_nets" title="Permalink to this headline">#</a></h2>
<p>Contains torch Modules for policy networks. These networks take an
observation dictionary as input (and possibly additional conditioning,
such as subgoal or goal dictionaries) and produce action predictions,
samples, or distributions as outputs. Note that actions
are assumed to lie in [-1, 1], and most networks will have a final
tanh activation to help ensure this range.</p>
<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.ActorNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></span><span class="sig-name descname"><span class="pre">ActorNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.ActorNetwork" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.obs_nets.MIMO_MLP" title="robomimic.models.obs_nets.MIMO_MLP"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.obs_nets.MIMO_MLP</span></code></a></p>
<p>A basic policy network that predicts actions from observations.
Can optionally be goal conditioned on future observations.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.ActorNetwork.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.ActorNetwork.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Process each set of inputs in its own observation group.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>dict</em>) – a dictionary of dictionaries with one dictionary per
observation group. Each observation group’s dictionary should map
modality to torch.Tensor batches. Should be consistent with
&#64;self.input_obs_group_shapes.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>dictionary of output torch.Tensors, that corresponds</dt><dd><p>to &#64;self.output_shapes</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>outputs (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.ActorNetwork.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.ActorNetwork.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Returns output shape for this module, which is a dictionary instead
of a list since outputs are dictionaries.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.ActorNetwork.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.ActorNetwork.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.GMMActorNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></span><span class="sig-name descname"><span class="pre">GMMActorNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_modes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'softplus'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_noise_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_tanh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.GMMActorNetwork" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.policy_nets.ActorNetwork" title="robomimic.models.policy_nets.ActorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.policy_nets.ActorNetwork</span></code></a></p>
<p>Variant of actor network that learns a multimodal Gaussian mixture distribution
over actions.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.GMMActorNetwork.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.GMMActorNetwork.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Samples actions from the policy distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>batch of actions from policy distribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>action (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.GMMActorNetwork.forward_train">
<span class="sig-name descname"><span class="pre">forward_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.GMMActorNetwork.forward_train" title="Permalink to this definition">#</a></dt>
<dd><p>Return full GMM distribution, which is useful for computing
quantities necessary at train-time, like log-likelihood, KL
divergence, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>GMM distribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dist (Distribution)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.GMMActorNetwork.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.GMMActorNetwork.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.GaussianActorNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></span><span class="sig-name descname"><span class="pre">GaussianActorNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'softplus'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_last_fc_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_limits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(-</span> <span class="pre">9.0,</span> <span class="pre">9.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_limits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.007,</span> <span class="pre">7.5)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_noise_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_tanh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.GaussianActorNetwork" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.policy_nets.ActorNetwork" title="robomimic.models.policy_nets.ActorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.policy_nets.ActorNetwork</span></code></a></p>
<p>Variant of actor network that learns a diagonal unimodal Gaussian distribution
over actions.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.GaussianActorNetwork.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.GaussianActorNetwork.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Samples actions from the policy distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>batch of actions from policy distribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>action (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.GaussianActorNetwork.forward_train">
<span class="sig-name descname"><span class="pre">forward_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.GaussianActorNetwork.forward_train" title="Permalink to this definition">#</a></dt>
<dd><p>Return full Gaussian distribution, which is useful for computing
quantities necessary at train-time, like log-likelihood, KL
divergence, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Gaussian distribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dist (Distribution)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.GaussianActorNetwork.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.GaussianActorNetwork.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.PerturbationActorNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></span><span class="sig-name descname"><span class="pre">PerturbationActorNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbation_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.PerturbationActorNetwork" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.policy_nets.ActorNetwork" title="robomimic.models.policy_nets.ActorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.policy_nets.ActorNetwork</span></code></a></p>
<p>An action perturbation network - primarily used in BCQ.
It takes states and actions and returns action perturbations.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.PerturbationActorNetwork.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.PerturbationActorNetwork.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Forward pass through perturbation actor.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.PerturbationActorNetwork.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.PerturbationActorNetwork.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.RNNActorNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></span><span class="sig-name descname"><span class="pre">RNNActorNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_hidden_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'LSTM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNActorNetwork" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.obs_nets.RNN_MIMO_MLP" title="robomimic.models.obs_nets.RNN_MIMO_MLP"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.obs_nets.RNN_MIMO_MLP</span></code></a></p>
<p>An RNN policy network that predicts actions from observations.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.RNNActorNetwork.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_init_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNActorNetwork.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Forward a sequence of inputs through the RNN and the per-step network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations - each tensor in the dictionary
should have leading dimensions batch and time [B, T, …]</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
<li><p><strong>rnn_init_state</strong> – rnn hidden state, initialize to zero state if set to None</p></li>
<li><p><strong>return_state</strong> (<em>bool</em>) – whether to return hidden state</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>predicted action sequence
rnn_state: return rnn state at the end if return_state is set to True</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>actions (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.RNNActorNetwork.forward_step">
<span class="sig-name descname"><span class="pre">forward_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNActorNetwork.forward_step" title="Permalink to this definition">#</a></dt>
<dd><p>Unroll RNN over single timestep to get actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations. Should not contain
time dimension.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
<li><p><strong>rnn_state</strong> – rnn hidden state, initialize to zero state if set to None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>batch of actions - does not contain time dimension
state: updated rnn state</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>actions (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.RNNActorNetwork.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNActorNetwork.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Returns output shape for this module, which is a dictionary instead
of a list since outputs are dictionaries.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>dict</em>) – dictionary of dictionaries, where each top-level key
corresponds to an observation group, and the low-level dictionaries
specify the shape for each modality in an observation dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.RNNActorNetwork.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.RNNActorNetwork.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.RNNGMMActorNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></span><span class="sig-name descname"><span class="pre">RNNGMMActorNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_hidden_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'LSTM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_modes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'softplus'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_noise_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_tanh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNGMMActorNetwork" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.policy_nets.RNNActorNetwork" title="robomimic.models.policy_nets.RNNActorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.policy_nets.RNNActorNetwork</span></code></a></p>
<p>An RNN GMM policy network that predicts sequences of action distributions from observation sequences.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.RNNGMMActorNetwork.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_init_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNGMMActorNetwork.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Samples actions from the policy distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>batch of actions from policy distribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>action (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.RNNGMMActorNetwork.forward_step">
<span class="sig-name descname"><span class="pre">forward_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNGMMActorNetwork.forward_step" title="Permalink to this definition">#</a></dt>
<dd><p>Unroll RNN over single timestep to get sampled actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations. Should not contain
time dimension.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
<li><p><strong>rnn_state</strong> – rnn hidden state, initialize to zero state if set to None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>batch of actions - does not contain time dimension
state: updated rnn state</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>acts (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.RNNGMMActorNetwork.forward_train">
<span class="sig-name descname"><span class="pre">forward_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_init_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNGMMActorNetwork.forward_train" title="Permalink to this definition">#</a></dt>
<dd><p>Return full GMM distribution, which is useful for computing
quantities necessary at train-time, like log-likelihood, KL
divergence, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
<li><p><strong>rnn_init_state</strong> – rnn hidden state, initialize to zero state if set to None</p></li>
<li><p><strong>return_state</strong> (<em>bool</em>) – whether to return hidden state</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>sequence of GMM distributions over the timesteps
rnn_state: return rnn state at the end if return_state is set to True</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dists (Distribution)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.RNNGMMActorNetwork.forward_train_step">
<span class="sig-name descname"><span class="pre">forward_train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.RNNGMMActorNetwork.forward_train_step" title="Permalink to this definition">#</a></dt>
<dd><p>Unroll RNN over single timestep to get action GMM distribution, which
is useful for computing quantities necessary at train-time, like
log-likelihood, KL divergence, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations. Should not contain
time dimension.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
<li><p><strong>rnn_state</strong> – rnn hidden state, initialize to zero state if set to None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>GMM action distributions
state: updated rnn state</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ad (Distribution)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.RNNGMMActorNetwork.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.RNNGMMActorNetwork.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.TransformerActorNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></span><span class="sig-name descname"><span class="pre">TransformerActorNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_embed_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_num_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_context_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_emb_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_attn_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_block_output_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_sinusoidal_embedding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_nn_parameter_for_timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.TransformerActorNetwork" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.obs_nets.MIMO_Transformer" title="robomimic.models.obs_nets.MIMO_Transformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.obs_nets.MIMO_Transformer</span></code></a></p>
<p>An Transformer policy network that predicts actions from observation sequences (assumed to be frame stacked
from previous observations) and possible from previous actions as well (in an autoregressive manner).</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.TransformerActorNetwork.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">actions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.TransformerActorNetwork.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Forward a sequence of inputs through the Transformer.
:param obs_dict: batch of observations - each tensor in the dictionary</p>
<blockquote>
<div><p>should have leading dimensions batch and time [B, T, …]</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions</strong> (<em>torch.Tensor</em>) – batch of actions of shape [B, T, D]</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>contains predicted action sequence, or dictionary</dt><dd><p>with predicted action sequence and predicted observation sequences</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>outputs (torch.Tensor or dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.TransformerActorNetwork.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.TransformerActorNetwork.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Returns output shape for this module, which is a dictionary instead
of a list since outputs are dictionaries.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.TransformerActorNetwork.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.TransformerActorNetwork.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.TransformerGMMActorNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></span><span class="sig-name descname"><span class="pre">TransformerGMMActorNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_embed_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_num_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_context_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_emb_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_attn_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_block_output_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_sinusoidal_embedding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_nn_parameter_for_timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_modes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'softplus'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_noise_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_tanh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.TransformerGMMActorNetwork" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.policy_nets.TransformerActorNetwork" title="robomimic.models.policy_nets.TransformerActorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.policy_nets.TransformerActorNetwork</span></code></a></p>
<p>A Transformer GMM policy network that predicts sequences of action distributions from observation
sequences (assumed to be frame stacked from previous observations).</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.TransformerGMMActorNetwork.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">actions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.TransformerGMMActorNetwork.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Samples actions from the policy distribution.
:param obs_dict: batch of observations
:type obs_dict: dict
:param actions: batch of actions
:type actions: torch.Tensor
:param goal_dict: if not None, batch of goal observations
:type goal_dict: dict</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>batch of actions from policy distribution</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>action (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.TransformerGMMActorNetwork.forward_train">
<span class="sig-name descname"><span class="pre">forward_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">actions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_noise_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.TransformerGMMActorNetwork.forward_train" title="Permalink to this definition">#</a></dt>
<dd><p>Return full GMM distribution, which is useful for computing
quantities necessary at train-time, like log-likelihood, KL
divergence, etc.
:param obs_dict: batch of observations
:type obs_dict: dict
:param actions: batch of actions
:type actions: torch.Tensor
:param goal_dict: if not None, batch of goal observations
:type goal_dict: dict</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>sequence of GMM distributions over the timesteps</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dists (Distribution)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.TransformerGMMActorNetwork.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.TransformerGMMActorNetwork.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.VAEActor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.policy_nets.</span></span><span class="sig-name descname"><span class="pre">VAEActor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_is_conditioned</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_reconstruction_sum_across_elements</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_clip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_learn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_is_conditioned</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_layer_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_use_gmm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_gmm_num_modes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_gmm_learn_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_use_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_categorical_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_categorical_gumbel_softmax_hard</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>A VAE that models a distribution of actions conditioned on observations.
The VAE prior and decoder are used at test-time as the policy.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.VAEActor.decode">
<span class="sig-name descname"><span class="pre">decode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.decode" title="Permalink to this definition">#</a></dt>
<dd><p>Thin wrapper around &#64;VaeNets.VAE implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. Only needs to be provided if &#64;decoder_is_conditioned
or &#64;z is None (since the prior will require it to generate z).</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities.</p></li>
<li><p><strong>z</strong> (<em>torch.Tensor</em>) – if provided, these latents are used to generate
reconstructions from the VAE, and the prior is not sampled.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – this argument is used to specify the number of samples to
generate from the prior. Only required if &#64;z is None - i.e.
sampling takes place</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>dictionary of reconstructed inputs (this will be a dictionary</dt><dd><p>with a single “action” key)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>recons (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.VAEActor.encode">
<span class="sig-name descname"><span class="pre">encode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.encode" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions</strong> (<em>torch.Tensor</em>) – a batch of actions</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to the observation modalities
used for conditioning in either the decoder or the prior (or both).</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>dictionary with the following keys:</p>
<blockquote>
<div><p>mean (torch.Tensor): posterior encoder means</p>
<p>logvar (torch.Tensor): posterior encoder logvars</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>posterior params (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.VAEActor.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Samples actions from the policy distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
<li><p><strong>z</strong> (<em>torch.Tensor</em>) – if not None, use the provided batch of latents instead
of sampling from the prior</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>batch of actions from policy distribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>action (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.VAEActor.forward_train">
<span class="sig-name descname"><span class="pre">forward_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freeze_encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.forward_train" title="Permalink to this definition">#</a></dt>
<dd><p>A full pass through the VAE network used during training to construct KL
and reconstruction losses. See &#64;VAE class for more info.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions</strong> (<em>torch.Tensor</em>) – a batch of actions</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to the observation modalities
used for conditioning in either the decoder or the prior (or both).</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>a dictionary that contains the following outputs.</p>
<blockquote>
<div><dl class="simple">
<dt>encoder_params (dict): parameters for the posterior distribution</dt><dd><p>from the encoder forward pass</p>
</dd>
</dl>
<p>encoder_z (torch.Tensor): latents sampled from the encoder posterior</p>
<p>decoder_outputs (dict): action reconstructions from the decoder</p>
<p>kl_loss (torch.Tensor): KL loss over the batch of data</p>
<p>reconstruction_loss (torch.Tensor): reconstruction loss over the batch of data</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>vae_outputs (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.VAEActor.get_gumbel_temperature">
<span class="sig-name descname"><span class="pre">get_gumbel_temperature</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.get_gumbel_temperature" title="Permalink to this definition">#</a></dt>
<dd><p>Return current Gumbel-Softmax temperature. Should only be used if
&#64;prior_use_categorical is True.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.VAEActor.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>This implementation is required by the Module superclass, but is unused since we
never chain this module to other ones.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.VAEActor.sample_prior">
<span class="sig-name descname"><span class="pre">sample_prior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.sample_prior" title="Permalink to this definition">#</a></dt>
<dd><p>Thin wrapper around &#64;VaeNets.VAE implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<em>int</em>) – this argument is used to specify the number
of samples to generate from the prior.</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. Only needs to be provided if &#64;prior_is_conditioned.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>latents sampled from the prior</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>z (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.VAEActor.set_gumbel_temperature">
<span class="sig-name descname"><span class="pre">set_gumbel_temperature</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">temperature</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.set_gumbel_temperature" title="Permalink to this definition">#</a></dt>
<dd><p>Used by external algorithms to schedule Gumbel-Softmax temperature,
which is used during reparametrization at train-time. Should only be
used if &#64;prior_use_categorical is True.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.policy_nets.VAEActor.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.policy_nets.VAEActor.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-robomimic.models.transformers">
<span id="robomimic-models-transformers-module"></span><h2>robomimic.models.transformers module<a class="headerlink" href="#module-robomimic.models.transformers" title="Permalink to this headline">#</a></h2>
<p>Implementation of transformers, mostly based on Andrej’s minGPT model.
See <a class="reference external" href="https://github.com/karpathy/minGPT/blob/master/mingpt/model.py">https://github.com/karpathy/minGPT/blob/master/mingpt/model.py</a>
for more details.</p>
<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.transformers.CausalSelfAttention">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.transformers.</span></span><span class="sig-name descname"><span class="pre">CausalSelfAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embed_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.transformers.CausalSelfAttention" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.transformers.CausalSelfAttention.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.transformers.CausalSelfAttention.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Forward pass through Self-Attention block.
Input should be shape (B, T, D) where B is batch size, T is seq length (&#64;self.context_length), and
D is input dimension (&#64;self.embed_dim).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.transformers.CausalSelfAttention.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.transformers.CausalSelfAttention.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.transformers.CausalSelfAttention.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.transformers.CausalSelfAttention.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.transformers.GEGLU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.transformers.</span></span><span class="sig-name descname"><span class="pre">GEGLU</span></span><a class="headerlink" href="#robomimic.models.transformers.GEGLU" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p class="rubric">References</p>
<p>Shazeer et al., “GLU Variants Improve Transformer,” 2020.
<a class="reference external" href="https://arxiv.org/abs/2002.05202">https://arxiv.org/abs/2002.05202</a></p>
<p>Implementation: <a class="reference external" href="https://github.com/pfnet-research/deep-table/blob/237c8be8a405349ce6ab78075234c60d9bfe60b7/deep_table/nn/layers/activation.py">https://github.com/pfnet-research/deep-table/blob/237c8be8a405349ce6ab78075234c60d9bfe60b7/deep_table/nn/layers/activation.py</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.transformers.GEGLU.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.transformers.GEGLU.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.transformers.GEGLU.geglu">
<span class="sig-name descname"><span class="pre">geglu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.transformers.GEGLU.geglu" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.transformers.GEGLU.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.transformers.GEGLU.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.transformers.GPT_Backbone">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.transformers.</span></span><span class="sig-name descname"><span class="pre">GPT_Backbone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embed_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_output_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.transformers.GPT_Backbone" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>the GPT model, with a context size of block_size</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.transformers.GPT_Backbone.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.transformers.GPT_Backbone.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.transformers.GPT_Backbone.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.transformers.GPT_Backbone.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.transformers.GPT_Backbone.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.transformers.GPT_Backbone.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.transformers.PositionalEncoding">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.transformers.</span></span><span class="sig-name descname"><span class="pre">PositionalEncoding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embed_dim</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.transformers.PositionalEncoding" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Taken from <a class="reference external" href="https://pytorch.org/tutorials/beginner/transformer_tutorial.html">https://pytorch.org/tutorials/beginner/transformer_tutorial.html</a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.transformers.PositionalEncoding.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.transformers.PositionalEncoding.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Input timestep of shape BxT</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.transformers.PositionalEncoding.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.transformers.PositionalEncoding.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.transformers.SelfAttentionBlock">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.transformers.</span></span><span class="sig-name descname"><span class="pre">SelfAttentionBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embed_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">GELU()</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.transformers.SelfAttentionBlock" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>A single Transformer Block, that can be chained together repeatedly.
It consists of a &#64;CausalSelfAttention module and a small MLP, along with
layer normalization and residual connections on each input.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.transformers.SelfAttentionBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.transformers.SelfAttentionBlock.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Forward pass - chain self-attention + MLP blocks, with residual connections and layer norms.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.transformers.SelfAttentionBlock.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.transformers.SelfAttentionBlock.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.transformers.SelfAttentionBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.transformers.SelfAttentionBlock.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-robomimic.models.vae_nets">
<span id="robomimic-models-vae-nets-module"></span><h2>robomimic.models.vae_nets module<a class="headerlink" href="#module-robomimic.models.vae_nets" title="Permalink to this headline">#</a></h2>
<p>Contains an implementation of Variational Autoencoder (VAE) and other
variants, including other priors, and RNN-VAEs.</p>
<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.CategoricalPrior">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.vae_nets.</span></span><span class="sig-name descname"><span class="pre">CategoricalPrior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learnable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.CategoricalPrior" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.vae_nets.Prior" title="robomimic.models.vae_nets.Prior"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.vae_nets.Prior</span></code></a></p>
<p>A class that holds functionality for learning categorical priors for use
in VAEs.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.CategoricalPrior.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.CategoricalPrior.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Computes prior logits (unnormalized log-probs).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size - this is needed for parameters that are
not obs-dependent, to make sure the leading dimension is correct
for downstream sampling and loss computation purposes</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary containing prior parameters</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>prior_params (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.CategoricalPrior.kl_loss">
<span class="sig-name descname"><span class="pre">kl_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.CategoricalPrior.kl_loss" title="Permalink to this definition">#</a></dt>
<dd><p>Computes KL divergence loss between the Categorical distribution
given by the unnormalized logits &#64;logits and the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior_params</strong> (<em>dict</em>) – dictionary with key “logits” corresponding
to torch.Tensor batch of unnormalized logits of shape [B, D * C]
that corresponds to the posterior categorical distribution</p></li>
<li><p><strong>z</strong> (<em>torch.Tensor</em>) – samples from encoder - unused for this prior</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>KL divergence loss</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>kl_loss (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.CategoricalPrior.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.CategoricalPrior.sample" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a batch of samples from the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<em>int</em>) – this argument is used to specify the number
of samples to generate from the prior.</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent. Leading dimension should
be consistent with &#64;n, the number of samples to generate.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>batch of sampled latent vectors.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>z (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.CategoricalPrior.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.vae_nets.CategoricalPrior.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.GaussianPrior">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.vae_nets.</span></span><span class="sig-name descname"><span class="pre">GaussianPrior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_clip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learnable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_gmm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gmm_num_modes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gmm_learn_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.GaussianPrior" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.vae_nets.Prior" title="robomimic.models.vae_nets.Prior"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.vae_nets.Prior</span></code></a></p>
<p>A class that holds functionality for learning both unimodal Gaussian priors and
multimodal Gaussian Mixture Model priors for use in VAEs.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.GaussianPrior.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.GaussianPrior.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Computes means, logvars, and GMM weights (if using GMM and learning weights).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size - this is needed for parameters that are
not obs-dependent, to make sure the leading dimension is correct
for downstream sampling and loss computation purposes</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary containing prior parameters</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>prior_params (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.GaussianPrior.kl_loss">
<span class="sig-name descname"><span class="pre">kl_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.GaussianPrior.kl_loss" title="Permalink to this definition">#</a></dt>
<dd><p>Computes sample-based KL divergence loss between the Gaussian distribution
given by &#64;mu, &#64;logvar and the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior_params</strong> (<em>dict</em>) – dictionary with keys “mu” and “logvar” corresponding
to torch.Tensor batch of means and log-variances of posterior Gaussian
distribution.</p></li>
<li><p><strong>z</strong> (<em>torch.Tensor</em>) – samples from the Gaussian distribution parametrized by
&#64;mu and &#64;logvar. Only needed if &#64;self.use_gmm is True.</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>KL divergence loss</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>kl_loss (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.GaussianPrior.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.GaussianPrior.sample" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a batch of samples from the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<em>int</em>) – this argument is used to specify the number
of samples to generate from the prior.</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent. Leading dimension should
be consistent with &#64;n, the number of samples to generate.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>batch of sampled latent vectors.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>z (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.GaussianPrior.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.vae_nets.GaussianPrior.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.Prior">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.vae_nets.</span></span><span class="sig-name descname"><span class="pre">Prior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">param_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_obs_dependent</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.Prior" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.base_nets.Module" title="robomimic.models.base_nets.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.base_nets.Module</span></code></a></p>
<p>Base class for VAE priors. It’s basically the same as a &#64;MIMO_MLP network (it
instantiates one) but it supports additional methods such as KL loss computation
and sampling, and also may learn prior parameters as observation-independent
torch Parameters instead of observation-dependent mappings.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.Prior.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.Prior.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Computes prior parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size - this is needed for parameters that are
not obs-dependent, to make sure the leading dimension is correct
for downstream sampling and loss computation purposes</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary containing prior parameters</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>prior_params (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.Prior.kl_loss">
<span class="sig-name descname"><span class="pre">kl_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.Prior.kl_loss" title="Permalink to this definition">#</a></dt>
<dd><p>Computes sample-based KL divergence loss between the Gaussian distribution
given by &#64;mu, &#64;logvar and the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior_params</strong> (<em>dict</em>) – dictionary with keys “mu” and “logvar” corresponding
to torch.Tensor batch of means and log-variances of posterior Gaussian
distribution.</p></li>
<li><p><strong>z</strong> (<em>torch.Tensor</em>) – samples from the Gaussian distribution parametrized by
&#64;mu and &#64;logvar. May not be needed depending on the prior.</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>KL divergence loss</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>kl_loss (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.Prior.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.Prior.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Returns output shape for this module, which is a dictionary instead
of a list since outputs are dictionaries.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.Prior.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.Prior.sample" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a batch of samples from the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<em>int</em>) – this argument is used to specify the number
of samples to generate from the prior.</p></li>
<li><p><strong>obs_dict</strong> (<em>dict</em>) – inputs according to &#64;obs_shapes. Only needs to be provided
if any prior parameters are obs-dependent. Leading dimension should
be consistent with &#64;n, the number of samples to generate.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>batch of sampled latent vectors.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>z (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.Prior.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.vae_nets.Prior.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.VAE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.vae_nets.</span></span><span class="sig-name descname"><span class="pre">VAE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_is_conditioned</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_reconstruction_sum_across_elements</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_clip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_squash</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_scales</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_ranges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_learn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_is_conditioned</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_layer_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_use_gmm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_gmm_num_modes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_gmm_learn_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_use_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_categorical_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_categorical_gumbel_softmax_hard</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A Variational Autoencoder (VAE), as described in <a class="reference external" href="https://arxiv.org/abs/1312.6114">https://arxiv.org/abs/1312.6114</a>.</p>
<p>Models a distribution p(X) or a conditional distribution p(X | Y), where each
variable can consist of multiple modalities. The target variable X, whose
distribution is modeled, is specified through the &#64;input_shapes argument,
which is a map between modalities (strings) and expected shapes. In this way,
a variable that consists of multiple kinds of data (e.g. image and flat-dimensional)
can be modeled as well. A separate &#64;output_shapes argument is used to specify the
expected reconstructions - this allows for asymmetric reconstruction (for example,
reconstructing low-resolution images).</p>
<p>This implementation supports learning conditional distributions as well (cVAE).
The conditioning variable Y is specified through the &#64;condition_shapes argument,
which is also a map between modalities (strings) and expected shapes. In this way,
variables with multiple kinds of data (e.g. image and flat-dimensional) can
jointly be conditioned on. By default, the decoder takes the conditioning
variable Y as input. To force the decoder to reconstruct from just the latent,
set &#64;decoder_is_conditioned to False (in this case, the prior must be conditioned).</p>
<p>The implementation also supports learning expressive priors instead of using
the usual N(0, 1) prior. There are three kinds of priors supported - Gaussian,
Gaussian Mixture Model (GMM), and Categorical. For each prior, the parameters can
be learned as independent parameters, or be learned as functions of the conditioning
variable Y (by setting &#64;prior_is_conditioned).</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.VAE.decode">
<span class="sig-name descname"><span class="pre">decode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.decode" title="Permalink to this definition">#</a></dt>
<dd><p>Pass latents through decoder. Latents should be passed in to
this function at train-time for backpropagation, but they
can be left out at test-time. In this case, latents will
be sampled using the VAE prior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>conditions</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to the modalities used for conditioning
in either the decoder or the prior (or both). Only for cVAEs.</p></li>
<li><p><strong>goals</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities. Only for cVAEs.</p></li>
<li><p><strong>z</strong> (<em>torch.Tensor</em>) – if provided, these latents are used to generate
reconstructions from the VAE, and the prior is not sampled.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – this argument is used to specify the number of samples to
generate from the prior. Only required if &#64;z is None - i.e.
sampling takes place</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary of reconstructed inputs</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>recons (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.VAE.encode">
<span class="sig-name descname"><span class="pre">encode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.encode" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>dict</em>) – a dictionary that maps input modalities to torch.Tensor
batches. These should correspond to the encoder-only modalities
(i.e. &#64;self.encoder_only_shapes).</p></li>
<li><p><strong>conditions</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to the modalities used for conditioning
in either the decoder or the prior (or both). Only for cVAEs.</p></li>
<li><p><strong>goals</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities. Only for cVAEs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary with posterior parameters</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>posterior params (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.VAE.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freeze_encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.forward" title="Permalink to this definition">#</a></dt>
<dd><p>A full pass through the VAE network to construct KL and reconstruction
losses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>dict</em>) – a dictionary that maps input modalities to torch.Tensor
batches. These should correspond to the encoder-only modalities
(i.e. &#64;self.encoder_only_shapes).</p></li>
<li><p><strong>outputs</strong> (<em>dict</em>) – a dictionary that maps output modalities to torch.Tensor
batches. These should correspond to the modalities used for
reconstruction (i.e. &#64;self.output_shapes).</p></li>
<li><p><strong>conditions</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to the modalities used for conditioning
in either the decoder or the prior (or both). Only for cVAEs.</p></li>
<li><p><strong>goals</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities. Only for cVAEs.</p></li>
<li><p><strong>freeze_encoder</strong> (<em>bool</em>) – if True, don’t backprop into encoder by detaching
encoder outputs. Useful for doing staged VAE training.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>a dictionary that contains the following outputs.</p>
<blockquote>
<div><dl class="simple">
<dt>encoder_params (dict): parameters for the posterior distribution</dt><dd><p>from the encoder forward pass</p>
</dd>
</dl>
<p>encoder_z (torch.Tensor): latents sampled from the encoder posterior</p>
<p>decoder_outputs (dict): reconstructions from the decoder</p>
<p>kl_loss (torch.Tensor): KL loss over the batch of data</p>
<p>reconstruction_loss (torch.Tensor): reconstruction loss over the batch of data</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>vae_outputs (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.VAE.get_gumbel_temperature">
<span class="sig-name descname"><span class="pre">get_gumbel_temperature</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.get_gumbel_temperature" title="Permalink to this definition">#</a></dt>
<dd><p>Return current Gumbel-Softmax temperature. Should only be used if
&#64;self.prior_use_categorical is True.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.VAE.kl_loss">
<span class="sig-name descname"><span class="pre">kl_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.kl_loss" title="Permalink to this definition">#</a></dt>
<dd><p>Computes KL divergence loss given the results of the VAE encoder forward
pass and the conditioning and goal modalities (if the prior is input-dependent).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior_params</strong> (<em>dict</em>) – dictionary with keys “mu” and “logvar” corresponding
to torch.Tensor batch of means and log-variances of posterior Gaussian
distribution. This is the output of &#64;self.encode.</p></li>
<li><p><strong>encoder_z</strong> (<em>torch.Tensor</em>) – samples from the Gaussian distribution parametrized by
&#64;mu and &#64;logvar. Only required if using a GMM prior.</p></li>
<li><p><strong>conditions</strong> (<em>dict</em>) – inputs according to &#64;self.condition_shapes. Only needs to be provided
if any prior parameters are input-dependent.</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – inputs according to &#64;self.goal_shapes (only if using goal observations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>VAE KL divergence loss</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>kl_loss (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.VAE.reconstruction_loss">
<span class="sig-name descname"><span class="pre">reconstruction_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reconstructions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.reconstruction_loss" title="Permalink to this definition">#</a></dt>
<dd><p>Reconstruction loss. Note that we compute the average per-dimension error
in each modality and then average across all the modalities.</p>
<p>The beta term for weighting between reconstruction and kl losses will
need to be tuned in practice for each situation (see
<a class="reference external" href="https://twitter.com/memotv/status/973323454350090240">https://twitter.com/memotv/status/973323454350090240</a> for more
discussion).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reconstructions</strong> (<em>dict</em>) – reconstructed inputs, consistent with
&#64;self.output_shapes</p></li>
<li><p><strong>targets</strong> (<em>dict</em>) – reconstruction targets, consistent with
&#64;self.output_shapes</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>VAE reconstruction loss</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>reconstruction_loss (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.VAE.reparameterize">
<span class="sig-name descname"><span class="pre">reparameterize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior_params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.reparameterize" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>params</strong> (<em>posterior</em>) – dictionary from encoder forward pass that
parametrizes the encoder distribution</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>sampled latents that are also differentiable</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>z (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.VAE.sample_prior">
<span class="sig-name descname"><span class="pre">sample_prior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.sample_prior" title="Permalink to this definition">#</a></dt>
<dd><p>Samples from the prior using the prior parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<em>int</em>) – this argument is used to specify the number
of samples to generate from the prior.</p></li>
<li><p><strong>conditions</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to the modalities used for conditioning
in either the decoder or the prior (or both). Only for cVAEs.</p></li>
<li><p><strong>goals</strong> (<em>dict</em>) – a dictionary that maps modalities to torch.Tensor
batches. These should correspond to goal modalities. Only for cVAEs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>sampled latents from the prior</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>z (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.VAE.set_gumbel_temperature">
<span class="sig-name descname"><span class="pre">set_gumbel_temperature</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">temperature</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.VAE.set_gumbel_temperature" title="Permalink to this definition">#</a></dt>
<dd><p>Used by external algorithms to schedule Gumbel-Softmax temperature,
which is used during reparametrization at train-time. Should only
be used if &#64;self.prior_use_categorical is True.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.VAE.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.vae_nets.VAE.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="robomimic.models.vae_nets.vae_args_from_config">
<span class="sig-prename descclassname"><span class="pre">robomimic.models.vae_nets.</span></span><span class="sig-name descname"><span class="pre">vae_args_from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vae_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.vae_nets.vae_args_from_config" title="Permalink to this definition">#</a></dt>
<dd><p>Generate a set of VAE args that are read from the VAE-specific part
of a config (for example see <cite>config.algo.vae</cite> in BCConfig).</p>
</dd></dl>

</section>
<section id="module-robomimic.models.value_nets">
<span id="robomimic-models-value-nets-module"></span><h2>robomimic.models.value_nets module<a class="headerlink" href="#module-robomimic.models.value_nets" title="Permalink to this headline">#</a></h2>
<p>Contains torch Modules for value networks. These networks take an
observation dictionary as input (and possibly additional conditioning,
such as subgoal or goal dictionaries) and produce value or
action-value estimates or distributions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.value_nets.ActionValueNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.value_nets.</span></span><span class="sig-name descname"><span class="pre">ActionValueNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.ActionValueNetwork" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.value_nets.ValueNetwork" title="robomimic.models.value_nets.ValueNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.value_nets.ValueNetwork</span></code></a></p>
<p>A basic Q (action-value) network that predicts values from observations
and actions. Can optionally be goal conditioned on future observations.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.value_nets.ActionValueNetwork.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.ActionValueNetwork.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Modify forward from super class to include actions in inputs.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.value_nets.ActionValueNetwork.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.value_nets.ActionValueNetwork.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.value_nets.DistributionalActionValueNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.value_nets.</span></span><span class="sig-name descname"><span class="pre">DistributionalActionValueNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_atoms</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.DistributionalActionValueNetwork" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.value_nets.ActionValueNetwork" title="robomimic.models.value_nets.ActionValueNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.value_nets.ActionValueNetwork</span></code></a></p>
<p>Distributional Q (action-value) network that outputs a categorical distribution over
a discrete grid of value atoms. See <a class="reference external" href="https://arxiv.org/pdf/1707.06887.pdf">https://arxiv.org/pdf/1707.06887.pdf</a> for
more details.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.value_nets.DistributionalActionValueNetwork.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.DistributionalActionValueNetwork.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Return mean of critic categorical distribution. Useful for obtaining
point estimates of critic values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>acts</strong> (<em>torch.Tensor</em>) – batch of actions</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>expectation of value distribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>mean_value (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.value_nets.DistributionalActionValueNetwork.forward_train">
<span class="sig-name descname"><span class="pre">forward_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.DistributionalActionValueNetwork.forward_train" title="Permalink to this definition">#</a></dt>
<dd><p>Return full critic categorical distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_dict</strong> (<em>dict</em>) – batch of observations</p></li>
<li><p><strong>acts</strong> (<em>torch.Tensor</em>) – batch of actions</p></li>
<li><p><strong>goal_dict</strong> (<em>dict</em>) – if not None, batch of goal observations</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>value_distribution (DiscreteValueDistribution instance)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.value_nets.DistributionalActionValueNetwork.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.value_nets.DistributionalActionValueNetwork.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="robomimic.models.value_nets.ValueNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">robomimic.models.value_nets.</span></span><span class="sig-name descname"><span class="pre">ValueNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shapes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.ValueNetwork" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#robomimic.models.obs_nets.MIMO_MLP" title="robomimic.models.obs_nets.MIMO_MLP"><code class="xref py py-class docutils literal notranslate"><span class="pre">robomimic.models.obs_nets.MIMO_MLP</span></code></a></p>
<p>A basic value network that predicts values from observations.
Can optionally be goal conditioned on future observations.</p>
<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.value_nets.ValueNetwork.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.ValueNetwork.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Forward through value network, and then optionally use tanh scaling.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="robomimic.models.value_nets.ValueNetwork.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#robomimic.models.value_nets.ValueNetwork.output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Function to compute output shape from inputs to this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>iterable of int</em>) – shape of input. Does not include batch dimension.
Some modules may not need this argument, if their output does not depend
on the size of the input, or if they assume fixed size input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of integers corresponding to output shape</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out_shape ([int])</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="robomimic.models.value_nets.ValueNetwork.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#robomimic.models.value_nets.ValueNetwork.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-robomimic.models">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-robomimic.models" title="Permalink to this headline">#</a></h2>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="robomimic.envs.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">robomimic.envs package</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="robomimic.utils.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">robomimic.utils package</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By the robomimic core team<br/>
  
      &copy; Copyright the robomimic core team, 2023.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>